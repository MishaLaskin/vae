{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchsummary import summary\n",
    "\n",
    "from pushover import notify\n",
    "from utils import makegif\n",
    "from random import randint\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import Image, display\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 94)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "dataset = datasets.ImageFolder(root='./rollouts', transform=transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor(), \n",
    "]))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=bs, shuffle=True)\n",
    "len(dataset.imgs), len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Creates image dataset of 32X32 images with 3 channels\n",
    "    requires numpy and cv2 to work\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, file_path, train=True, transform=None):\n",
    "        print('Loading data')\n",
    "        data = np.load(file_path, allow_pickle=True)\n",
    "        print('Done loading data')\n",
    "        data = np.array(data.item().get('image_observation'))\n",
    "\n",
    "        self.n = data.shape[0]\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.data[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = 0\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Done loading data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(200000, 6250)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_file_path = '/home/misha/research/vqvae/data/reacher_no_target_length100_paths_2000.npy'\n",
    "#data_file_path = '/home/misha/research/vqvae/data/two_blocks_length100_paths_100.npy'\n",
    "#data_file_path = '/home/misha/research/vqvae/data/just_place_length100_paths_50.npy'\n",
    "\n",
    "#training_data, validation_data, training_loader, validation_loader, x_train_var = utils.load_data_and_data_loaders('POINTMASS',data_file_path, 32)\n",
    "\n",
    "dataset = ImageDataset(data_file_path, train=True,\n",
    "                             transform=transforms.Compose([\n",
    "                                transforms.ToTensor(), \n",
    "                             ]))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=bs, shuffle=True)\n",
    "len(dataset), len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fixed input for debugging\n",
    "fixed_x, _ = next(iter(dataloader))\n",
    "save_image(fixed_x, 'real_image.png')\n",
    "\n",
    "Image('real_image.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnFlatten(nn.Module):\n",
    "    def forward(self, input, size=1024):\n",
    "        return input.view(input.size(0), size, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, img_dim=32,image_channels=3, h_dim=1024, z_dim=32,device=None):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        assert img_dim == 32 or img_dim == 64, 'img_dim must be 32 or 64'\n",
    "        if img_dim == 32:\n",
    "            self.encoder = nn.Sequential(\n",
    "                nn.Conv2d(image_channels, 32, kernel_size=4, stride=2),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(64, 256, kernel_size=4, stride=2),\n",
    "                nn.ReLU(),\n",
    "                Flatten()\n",
    "            ).to(device)\n",
    "            \n",
    "            self.decoder = nn.Sequential(\n",
    "                UnFlatten(),\n",
    "                nn.ConvTranspose2d(h_dim, 128, kernel_size=5, stride=2),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(128, 32, kernel_size=6, stride=2),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(32, image_channels, kernel_size=6, stride=2),\n",
    "                nn.Sigmoid(),\n",
    "            ).to(device)\n",
    "        \n",
    "        if img_dim == 64:\n",
    "            self.encoder = nn.Sequential(\n",
    "                nn.Conv2d(image_channels, 32, kernel_size=4, stride=2),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(64, 128, kernel_size=4, stride=2),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(128, 256, kernel_size=4, stride=2),\n",
    "                nn.ReLU(),\n",
    "                Flatten()\n",
    "            ).to(device)\n",
    "            \n",
    "            self.decoder = nn.Sequential(\n",
    "                UnFlatten(),\n",
    "                nn.ConvTranspose2d(h_dim, 128, kernel_size=5, stride=2),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(64, 32, kernel_size=6, stride=2),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(32, image_channels, kernel_size=6, stride=2),\n",
    "                nn.Sigmoid(),\n",
    "            ).to(device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(z_dim, h_dim)\n",
    "        \n",
    "        \n",
    "        self.device =device\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        # return torch.normal(mu, std)\n",
    "        esp = torch.randn(*mu.size()).to(self.device)        \n",
    "        z = mu + std * esp\n",
    "        return z\n",
    "    \n",
    "    def bottleneck(self, h):\n",
    "        mu, logvar = self.fc1(h), self.fc2(h)\n",
    "        \n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        z, mu, logvar = self.bottleneck(h)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = self.fc3(z)\n",
    "        z = self.decoder(z)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, mu, logvar = self.encode(x)\n",
    "        z = self.decode(z)\n",
    "        return z, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_channels = fixed_x.size(1)\n",
    "img_dim = fixed_x.size(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(img_dim=img_dim,image_channels=image_channels,device=device).to(device)\n",
    "#model.load_state_dict(torch.load('vae.torch', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(recon_x, x, mu, logvar):\n",
    "    x = x.to(device)\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, size_average=False)\n",
    "    # BCE = F.mse_loss(recon_x, x, size_average=False)\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD, BCE, KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rfr reconstructed\n",
    "!mkdir reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/25] Loss: 1875.991 1875.876 0.115\n",
      "Epoch[2/25] Loss: 1876.194 1876.080 0.114\n",
      "Epoch[3/25] Loss: 1876.226 1876.116 0.110\n",
      "Epoch[4/25] Loss: 1876.284 1876.170 0.113\n",
      "Epoch[5/25] Loss: 1875.243 1875.130 0.112\n",
      "Epoch[6/25] Loss: 1875.658 1875.546 0.112\n",
      "Epoch[7/25] Loss: 1876.222 1876.112 0.111\n",
      "Epoch[8/25] Loss: 1875.482 1875.368 0.114\n",
      "Epoch[9/25] Loss: 1875.781 1875.669 0.112\n",
      "Epoch[10/25] Loss: 1875.061 1874.948 0.114\n",
      "Epoch[11/25] Loss: 1875.388 1875.275 0.113\n",
      "Epoch[12/25] Loss: 1875.697 1875.580 0.118\n",
      "Epoch[13/25] Loss: 1875.207 1875.091 0.116\n",
      "Epoch[14/25] Loss: 1875.480 1875.366 0.113\n",
      "Epoch[15/25] Loss: 1875.464 1875.352 0.113\n",
      "Epoch[16/25] Loss: 1875.025 1874.917 0.109\n",
      "Epoch[17/25] Loss: 1876.064 1875.952 0.112\n",
      "Epoch[18/25] Loss: 1874.415 1874.299 0.116\n",
      "Epoch[19/25] Loss: 1874.819 1874.704 0.115\n",
      "Epoch[20/25] Loss: 1875.316 1875.201 0.114\n",
      "Epoch[21/25] Loss: 1875.096 1874.983 0.112\n",
      "Epoch[22/25] Loss: 1875.273 1875.160 0.113\n",
      "Epoch[23/25] Loss: 1874.991 1874.875 0.116\n",
      "Epoch[24/25] Loss: 1874.907 1874.795 0.112\n",
      "Epoch[25/25] Loss: 1875.688 1875.575 0.113\n"
     ]
    }
   ],
   "source": [
    "filename = 'reacher_vae.pth'\n",
    "epoch = 0\n",
    "while epoch < epochs:\n",
    "    \n",
    "    for idx, (images, _) in enumerate(dataloader):\n",
    "        recon_images, mu, logvar = model(images.to(device))\n",
    "        loss, bce, kld = loss_fn(recon_images, images, mu, logvar)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        to_print = \"Epoch[{}/{}] Loss: {:.3f} {:.3f} {:.3f}\".format(epoch+1, \n",
    "                                epochs, loss.item()/bs, bce.item()/bs, kld.item()/bs)\n",
    "        if idx % 100 == 0 and idx >0:\n",
    "            epoch+=1\n",
    "            print(to_print)\n",
    "            break\n",
    "\n",
    "# notify to android when finished training\n",
    "#notify(to_print, priority=1)\n",
    "\n",
    "torch.save(model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(x):\n",
    "    x=x.to(device)\n",
    "    recon_x, _, _ = model(x)\n",
    "    return torch.cat([x, recon_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "image/png": {
       "unconfined": true,
       "width": 700
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sample = torch.randn(bs, 1024)\n",
    "# compare_x = vae.decoder(sample)\n",
    "\n",
    "# fixed_x, _ = next(iter(dataloader))\n",
    "# fixed_x = fixed_x[:8]\n",
    "fixed_x = dataset[randint(1, 100)][0].unsqueeze(0)\n",
    "compare_x = compare(fixed_x)\n",
    "\n",
    "save_image(compare_x.data.cpu(), 'sample_image.png')\n",
    "display(Image('sample_image.png', width=700, unconfined=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
